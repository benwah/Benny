# 6-Node Neural Network Topology - Deployment Summary

## ğŸ¯ Topology Overview

Successfully deployed a custom 6-node neural network topology with the following configuration:

```
Input Server (16 inputs) â†’ nn0 â†’ nn1 â†’ nn2 â†’ nn3 â†’ nn4 â†’ nn5 â†’ Output Server (8 outputs)
     â†“                     â†“     â†“     â†“     â†“     â†“     â†“            â†“
  Web UI (8001)         16â†’12  4â†’8   4â†’6   6â†’8   8â†’10  10â†’12      Web UI (8002)
                         â†“8    â†“6    â†“8    â†“10   â†“12   â†“10
                         â†“4    â†“4    â†“6    â†“8    â†“10   â†“8
```

## ğŸ—ï¸ Architecture Details

### Neural Networks
- **nn0**: 16 â†’ 12 â†’ 8 â†’ 4 (Classic Hebbian learning)
- **nn1**: 4 â†’ 8 â†’ 6 â†’ 4 (Competitive Hebbian learning)
- **nn2**: 4 â†’ 6 â†’ 8 â†’ 6 (Oja Hebbian learning)
- **nn3**: 6 â†’ 8 â†’ 10 â†’ 8 (BCM Hebbian learning)
- **nn4**: 8 â†’ 10 â†’ 12 â†’ 10 (Anti-Hebbian learning)
- **nn5**: 10 â†’ 12 â†’ 10 â†’ 8 (Hybrid Hebbian learning)

### Servers
- **Input Server**: Accepts 16 inputs, web interface on port 8001
- **Output Server**: Displays 8 outputs, web interface on port 8002

## ğŸŒ Access Points

### Web Interfaces
- **Input Server**: http://localhost:8001
- **Output Server**: http://localhost:8002

### Neural Network Endpoints
- **nn0**: localhost:8080
- **nn1**: localhost:8081
- **nn2**: localhost:8082
- **nn3**: localhost:8083
- **nn4**: localhost:8084
- **nn5**: localhost:8085

## ğŸš€ Usage Instructions

### Starting the Topology
```bash
cd /workspace/Benny/docker
./neural-topology.sh start custom-6node
```

### Stopping the Topology
```bash
cd /workspace/Benny/docker
./neural-topology.sh stop custom-6node
```

### Checking Status
```bash
cd /workspace/Benny/docker
./neural-topology.sh status custom-6node
```

### Viewing Logs
```bash
# View all logs
sudo docker logs input-server
sudo docker logs nn0
sudo docker logs nn1
sudo docker logs nn2
sudo docker logs nn3
sudo docker logs nn4
sudo docker logs nn5
sudo docker logs output-server

# Or view specific container logs
sudo docker logs <container-name>
```

## ğŸ”§ Configuration Files

### Docker Compose
- **Main file**: `/workspace/Benny/docker/topologies/custom-6node.yml`
- **Documentation**: `/workspace/Benny/docker/topologies/README-custom-6node.md`

### Neural Network Configurations
- **nn0**: `/workspace/Benny/docker/config/nn0.toml` (16 inputs)
- **nn1**: `/workspace/Benny/docker/config/nn1.toml`
- **nn2**: `/workspace/Benny/docker/config/nn2.toml`
- **nn3**: `/workspace/Benny/docker/config/nn3.toml`
- **nn4**: `/workspace/Benny/docker/config/nn4.toml`
- **nn5**: `/workspace/Benny/docker/config/nn5.toml` (8 outputs)

## ğŸ“Š Features

### Hebbian Learning Modes
Each neural network uses a different Hebbian learning algorithm:
- **Classic**: Traditional Hebbian learning
- **Competitive**: Winner-take-all learning
- **Oja**: Normalized Hebbian learning
- **BCM**: Bienenstock-Cooper-Munro learning
- **Anti-Hebbian**: Negative correlation learning
- **Hybrid**: Combination of multiple modes

### Real-time Monitoring
- **Input Control**: Manual input control via web interface
- **Output Visualization**: Real-time output monitoring and charting
- **Network Status**: Connection status and health monitoring
- **Activity Logging**: Timestamped activity logs

## ğŸ”— Data Flow

1. **Input**: User provides 16 inputs via web interface (port 8001)
2. **Processing**: Data flows through 6 neural networks in sequence
3. **Learning**: Each network applies its specific Hebbian learning algorithm
4. **Output**: Final 8 outputs are displayed on web interface (port 8002)

## âœ… Verification

The topology has been successfully deployed and tested:
- âœ… All 8 containers are running
- âœ… Neural networks have correct architectures
- âœ… Input server accepts 16 inputs
- âœ… Output server expects 8 outputs
- âœ… Web interfaces are accessible
- âœ… Network communication is established

## ğŸ® Next Steps

1. **Access the web interfaces** to interact with the neural networks
2. **Send test inputs** through the input server interface
3. **Monitor outputs** on the output server dashboard
4. **Experiment with different input patterns** to see how the network learns
5. **Observe Hebbian learning** in action across different algorithms

The topology is now ready for experimentation and research!